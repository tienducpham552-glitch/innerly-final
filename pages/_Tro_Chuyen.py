import streamlit as st
import google.generativeai as genai

st.set_page_config(page_title="Innerly Chat", page_icon="üß∏")

# 1. C·∫•u h√¨nh API
api_key = st.secrets.get("GEMINI_API_KEY", "")
if not api_key:
    st.error("Ch∆∞a t√¨m th·∫•y API Key!")
    st.stop()

genai.configure(api_key=api_key)

# 2. KI·ªÇM TRA V√Ä CH·ªåN MODEL (Gi·∫£i ph√°p m·ªõi)
@st.cache_resource
def get_available_model():
    try:
        # Li·ªát k√™ t·∫•t c·∫£ c√°c model b·∫°n c√≥ quy·ªÅn truy c·∫≠p
        models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        # ∆Øu ti√™n c√°c b·∫£n 1.5 m·ªõi, n·∫øu kh√¥ng c√≥ th√¨ l√πi v·ªÅ c√°c b·∫£n c≈© h∆°n
        for target in ['models/gemini-1.5-flash', 'models/gemini-1.5-pro', 'models/gemini-pro']:
            if target in models:
                return target
        return models[0] if models else None
    except:
        return 'models/gemini-1.5-flash' # M·∫∑c ƒë·ªãnh n·∫øu l·ªói

target_model = get_available_model()

# 3. Giao di·ªán
st.title("üß∏ Tr√≤ Chuy·ªán c√πng Innerly")

if "messages" not in st.session_state:
    st.session_state.messages = []

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

if prompt := st.chat_input("Chia s·∫ª v·ªõi m√¨nh nh√©..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.write(prompt)

    with st.chat_message("assistant"):
        try:
            model = genai.GenerativeModel(target_model)
            response = model.generate_content(prompt)
            st.write(response.text)
            st.session_state.messages.append({"role": "assistant", "content": response.text})
        except Exception as e:
            st.error(f"L·ªói: {str(e)}")
            st.info(f"ƒêang c·ªë g·∫Øng s·ª≠ d·ª•ng model: {target_model}")
